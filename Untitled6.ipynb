{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8n7obm0V75GieWbMAa7bT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakrbn/visionfilager/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) نصب پیش‌نیازها\n",
        "!pip install --quiet torch torchvision facenet-pytorch pillow scikit-learn\n",
        "\n",
        "# 1) مانت کردن گوگل درایو\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2) ایمپورت‌ها\n",
        "import os, zipfile, glob, random, time\n",
        "from PIL import Image\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from facenet_pytorch import InceptionResnetV1, fixed_image_standardization\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 3) مسیر ZIP‌ها و استخراج\n",
        "RAW_ROOT = '/content/drive/MyDrive/fvc2002_zips'\n",
        "os.makedirs(RAW_ROOT, exist_ok=True)\n",
        "for fname in os.listdir(RAW_ROOT):\n",
        "    if fname.lower().endswith('.zip'):\n",
        "        zip_path = os.path.join(RAW_ROOT, fname)\n",
        "        out_dir  = os.path.join(RAW_ROOT, fname[:-4])\n",
        "        if not os.path.isdir(out_dir):\n",
        "            print(f\"Extracting {fname}\")\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "                zf.extractall(RAW_ROOT)\n",
        "\n",
        "# 4) لیست همه‌ی .tif\n",
        "tif_paths = glob.glob(os.path.join(RAW_ROOT, '**', '*.tif'), recursive=True)\n",
        "assert tif_paths, \"هیچ فایل .tif ای پیدا نشد!\"\n",
        "\n",
        "# 5) انتخاب ۵ سوژه‌ی اول و ساخت لیست داده\n",
        "subjects = sorted({os.path.basename(p).split('_')[0] for p in tif_paths})[:5]\n",
        "assert len(subjects)==5, f\"فقط {len(subjects)} سوژه پیدا شد!\"\n",
        "data = [(p, subjects.index(os.path.basename(p).split('_')[0]))\n",
        "        for p in tif_paths if os.path.basename(p).split('_')[0] in subjects]\n",
        "random.seed(42)\n",
        "random.shuffle(data)\n",
        "cut = int(0.8*len(data))\n",
        "train_list, test_list = data[:cut], data[cut:]\n",
        "print(f\"Subjects={subjects}\")\n",
        "print(f\"Train={len(train_list)}, Test={len(test_list)}\")\n",
        "\n",
        "# 6) Dataset و DataLoader\n",
        "tfm = transforms.Compose([\n",
        "    transforms.Resize((112,112)),\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "class FPList(Dataset):\n",
        "    def __init__(self, items, tfm):\n",
        "        self.items, self.tfm = items, tfm\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, i):\n",
        "        p, lbl = self.items[i]\n",
        "        img = Image.open(p).convert('L').convert('RGB')\n",
        "        return self.tfm(img), lbl\n",
        "\n",
        "BATCH = 16\n",
        "train_loader = DataLoader(FPList(train_list, tfm), batch_size=BATCH, shuffle=True, num_workers=2)\n",
        "test_loader  = DataLoader(FPList(test_list,  tfm), batch_size=BATCH, shuffle=False, num_workers=2)\n",
        "\n",
        "# 7) مدل: backbone + head\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "backbone = InceptionResnetV1(pretrained='vggface2').to(device)  # حالا می‌خواهیم آن را fine-tune کنیم\n",
        "head     = nn.Linear(512, len(subjects)).to(device)\n",
        "\n",
        "# 8) optimizer با دو نرخ یادگیری\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': backbone.parameters(), 'lr': 1e-5},\n",
        "    {'params': head.parameters(),     'lr': 1e-4},\n",
        "])\n",
        "epochs = 20\n",
        "reached75 = False\n",
        "\n",
        "# 9) حلقه‌ی آموزش + اعتبارسنجی و توقف زودهنگام روی 75٪\n",
        "for ep in range(1, epochs+1):\n",
        "    backbone.train()\n",
        "    head.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        emb = backbone(xb)\n",
        "        logits = head(emb)\n",
        "        loss = F.cross_entropy(logits, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    # اعتبارسنجی\n",
        "    backbone.eval()\n",
        "    head.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            xb = xb.to(device)\n",
        "            emb = backbone(xb)\n",
        "            logits = head(emb)\n",
        "            ps += logits.argmax(1).cpu().tolist()\n",
        "            ys += yb.tolist()\n",
        "    acc = accuracy_score(ys, ps)*100\n",
        "    print(f\"Epoch {ep:2d}  Loss={total_loss/len(train_loader):.4f}  ValAcc={acc:.2f}%\")\n",
        "    if not reached75 and acc>=75:\n",
        "        print(f\"✔️ 75% reached at epoch {ep}\")\n",
        "        reached75 = True\n",
        "    if reached75:\n",
        "        break\n",
        "\n",
        "# 10) سنجش سرعت inference تک‌تصویر\n",
        "backbone.eval(); head.eval()\n",
        "img,_ = test_loader.dataset[0]\n",
        "t0 = time.time()\n",
        "with torch.no_grad():\n",
        "    _ = head(backbone(img.unsqueeze(0).to(device)))\n",
        "print(\"Single-image inference:\", time.time()-t0, \"s\")\n",
        "\n",
        "# 11) ساخت پایگاه امبدینگ (enroll_db) روی CPU\n",
        "enroll_db = {}\n",
        "with torch.no_grad():\n",
        "    for idx, sub in enumerate(subjects):\n",
        "        samples = [p for p,l in train_list if l==idx][:5]\n",
        "        embs = []\n",
        "        for p in samples:\n",
        "            x = tfm(Image.open(p).convert('L').convert('RGB')).unsqueeze(0).to(device)\n",
        "            embs.append(backbone(x).cpu().squeeze(0))\n",
        "        enroll_db[sub] = torch.stack(embs).mean(0)\n",
        "\n",
        "# 12) شناسایی یک نمونه‌ی جدید\n",
        "path, true_lbl = test_list[0]\n",
        "with torch.no_grad():\n",
        "    feat = backbone(tfm(Image.open(path).convert('L').convert('RGB'))\n",
        "                    .unsqueeze(0).to(device)).cpu().squeeze(0)\n",
        "scores = { sub: F.cosine_similarity(\n",
        "             feat.unsqueeze(0), enroll_db[sub].unsqueeze(0)\n",
        "           ).item()\n",
        "           for sub in subjects }\n",
        "pred = max(scores, key=scores.get)\n",
        "print(f\"True={subjects[true_lbl]}  Pred={pred}  Score={scores[pred]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7R5jDXyvFVe",
        "outputId": "e99c4fc1-40b1-40ab-d8fa-423740c36ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Subjects=['101', '102', '103', '104', '105']\n",
            "Train=160, Test=40\n",
            "Device: cuda\n",
            "Epoch  1  Loss=1.6084  ValAcc=22.50%\n",
            "Epoch  2  Loss=1.5870  ValAcc=22.50%\n",
            "Epoch  3  Loss=1.5721  ValAcc=22.50%\n",
            "Epoch  4  Loss=1.5582  ValAcc=25.00%\n",
            "Epoch  5  Loss=1.5356  ValAcc=22.50%\n",
            "Epoch  6  Loss=1.5207  ValAcc=32.50%\n",
            "Epoch  7  Loss=1.5004  ValAcc=60.00%\n",
            "Epoch  8  Loss=1.4792  ValAcc=30.00%\n",
            "Epoch  9  Loss=1.4572  ValAcc=25.00%\n",
            "Epoch 10  Loss=1.4387  ValAcc=32.50%\n",
            "Epoch 11  Loss=1.3994  ValAcc=65.00%\n",
            "Epoch 12  Loss=1.3775  ValAcc=17.50%\n",
            "Epoch 13  Loss=1.3402  ValAcc=72.50%\n",
            "Epoch 14  Loss=1.3184  ValAcc=62.50%\n",
            "Epoch 15  Loss=1.2970  ValAcc=27.50%\n",
            "Epoch 16  Loss=1.2637  ValAcc=22.50%\n",
            "Epoch 17  Loss=1.2323  ValAcc=30.00%\n",
            "Epoch 18  Loss=1.2199  ValAcc=82.50%\n",
            "✔️ 75% reached at epoch 18\n",
            "Single-image inference: 0.020404815673828125 s\n",
            "True=101  Pred=101  Score=0.8841\n"
          ]
        }
      ]
    }
  ]
}